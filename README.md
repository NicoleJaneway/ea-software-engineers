# EA Software Engineers Awesome List [Awesome][awesome-link]

Doing Good Better for Technologists

An unofficial list of personal and open source projects that are relevant to EA Effective Altruism (or are at least deemed EA-adjacent by the contributors).

## Table of Contents

- [EA Software Engineers Awesome List ](#ea-software-engineers-awesome-list-)
  - [Table of Contents](#table-of-contents)
  - [Personal Projects](#personal-projects)
  - [Open Source Projects](#open-source-projects)
    - [AI Safety](#ai-safety)
    - [General](#general)
  - [Other Awesome Lists](#other-awesome-lists)
  - [Contribute](#contribute)
  - [Credits](#credits)
  - [License](#license)

## Personal Projects

Created by EA Software Engineers

- [Ideact.it ](https://app.ideact.it/)‚Äì A tool to evaluate different cause areas and ideas by assigning significance values to different variables. The tool tries to combine the ITN framework with personal factors and give a clear visulisation of this. (Zak)
- [Your Project Name]() ‚Äì A short description about your project

## Open Source Projects

Recommended by EA Software Engineers

##### AI Safety

- [AI Safety Info / Stampy](https://github.com/StampyAI/) - "a single-point-of-access to AI Safety, designed to route people to the information they need whatever stage of exploration they are at"
  - You can interact with the wiki [here](https://aisafety.info/)
  - Stampy is a chatbot written in Python which can serve as a conversational interface between a human and AI Safety Info (and more!). Currently, Stampy runs only on Rob Miles' Discord server but he's probably going to invade other online spaces too.
- [DecisionTransformerInterpretability](https://github.com/jbloomAus/DecisionTransformerInterpretability) ‚Äì mechanistic interpretability of Reinforcement Learning project ([read more](https://www.lesswrong.com/posts/bBuBDJBYHt39Q5zZy/decision-transformer-interpretability)) (POC: [Joseph Bloom](https://github.com/jbloomAus))
- [Transformer Lens](https://github.com/neelnanda-io/TransformerLens) ‚Äì library for doing mechanistic interpretability of GPT-2 Style language models. The goal of mechanistic interpretability is to take a trained model and reverse engineer the algorithms the model learned during training from its weights (POC: [Joseph Bloom](https://github.com/jbloomAus))
- [Tuned Lens](https://github.com/AlignmentResearch/tuned-lens) - tools for understanding how transformer predictions are built layer-by-layer

##### General

- [Advice for getting started in Open Source](https://gist.github.com/NicoleJaneway/45069ea3ec808c5507d0e69282976457)

## Other Awesome Lists

- [awesome-awesome](https://github.com/emijrp/awesome-awesome)
- [awesome-awesomeness](https://github.com/bayandin/awesome-awesomeness)
- [sindresorhus/awesome](https://github.com/sindresorhus/awesome)
- [The Warren](https://github.com/torchhound/warren)

## Contribute

Contributions welcome! Read the [contribution guidelines](CONTRIBUTING.md) first.

## Credits

This project was initially created with [Cookiecutter][cookiecutter] and the custom [cookiecutter-awesome][cookiecutter-awesome] üç™

## License

[CC0][cc0-link]

To the extent possible under law, Nicole Janeway has waived all copyright
and related or neighboring rights to this work. See [LICENSE](LICENSE).

[awesome-badge]: https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg
[awesome-link]: https://github.com/sindresorhus/awesome
[cc0-badge]: http://mirrors.creativecommons.org/presskit/buttons/88x31/svg/cc-zero.svg
[cc0-link]: https://creativecommons.org/publicdomain/zero/1.0/
[cookiecutter]: https://github.com/audreyr/cookiecutter
[cookiecutter-awesome]: https://github.com/moodule/cookiecutter-git
